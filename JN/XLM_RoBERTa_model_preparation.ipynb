{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "873e5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import global_vars\n",
    "import XLM_RoBERTA_model_execution\n",
    "#from XLM_RoBERTA_model_execution import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f5fcd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_savedir_buttons = 'V:/Uni/Thesis/Code/Thesis/buttons_model'\n",
    "model_savedir_dialog = 'V:/Uni/Thesis/Code/Thesis/dialogue_model'\n",
    "#classification_buttons_filename = 'V:/Uni/Thesis/Code/Thesis/Classification file for buttons.csv'\n",
    "classification_buttons_filename = 'V:/Uni/Thesis/Code/Thesis/Classification file for buttons.txt'\n",
    "\n",
    "classification_dialog_filename = 'V:/Uni/Thesis/Code/Thesis/Classification file for cookie dialog.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d093551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Cookie dialog model\n",
      "2: Buttons model model\n",
      "Which model would you like to train? 2\n",
      "How many runs do you want to do? 2\n"
     ]
    }
   ],
   "source": [
    "print('1: Cookie dialog model')\n",
    "print('2: Buttons model model')\n",
    "choice = int(input('Which model would you like to train? '))\n",
    "choice_runs = int(input('How many runs do you want to do? '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fdd03971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of dataset: 1155\n",
      "Length of training group: 808\n",
      "Length of eval group: 173\n",
      "Length of prediction group: 174\n",
      "\n",
      "ClassificationArgs(adafactor_beta1=None, adafactor_clip_threshold=1.0, adafactor_decay_rate=-0.8, adafactor_eps=(1e-30, 0.001), adafactor_relative_step=True, adafactor_scale_parameter=True, adafactor_warmup_init=True, adam_betas=(0.9, 0.999), adam_epsilon=1e-08, best_model_dir='V:/Uni/Thesis/Code/Thesis/buttons_model0/best_model/', cache_dir='V:/Uni/Thesis/Code/Thesis/buttons_model0/cache/', config={}, cosine_schedule_num_cycles=0.5, custom_layer_parameters=[], custom_parameter_groups=[], dataloader_num_workers=0, do_lower_case=True, dynamic_quantize=False, early_stopping_consider_epochs=False, early_stopping_delta=0.001, early_stopping_metric='mcc', early_stopping_metric_minimize=False, early_stopping_patience=5, encoding='utf-8', eval_batch_size=32, evaluate_during_training=True, evaluate_during_training_silent=True, evaluate_during_training_steps=33, evaluate_during_training_verbose=True, evaluate_each_epoch=True, fp16=True, gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, loss_type=None, loss_args={}, manual_seed=None, max_grad_norm=1.0, max_seq_length=64, model_name=None, model_type=None, multiprocessing_chunksize=-1, n_gpu=1, no_cache=False, no_save=False, not_saved_args=[], num_train_epochs=20, optimizer='AdamW', output_dir='V:/Uni/Thesis/Code/Thesis/buttons_model0/', overwrite_output_dir=False, polynomial_decay_schedule_lr_end=1e-07, polynomial_decay_schedule_power=1.0, process_count=6, quantized_model=False, reprocess_input_data=True, save_best_model=True, save_eval_checkpoints=False, save_model_every_epoch=False, save_optimizer_and_scheduler=True, save_steps=-1, scheduler='linear_schedule_with_warmup', silent=False, skip_special_tokens=True, tensorboard_dir=None, thread_count=None, tokenizer_name=None, tokenizer_type=None, train_batch_size=32, train_custom_parameters_only=False, use_cached_eval_features=False, use_early_stopping=True, use_hf_datasets=False, use_multiprocessing=True, use_multiprocessing_for_evaluation=False, wandb_kwargs={}, wandb_project=None, warmup_ratio=0.06, warmup_steps=0, weight_decay=0.0, model_class='ClassificationModel', labels_list=['ACCEPT', 'DECLINE', 'MODIFY', 'SAVE', 'OTHER'], labels_map={}, lazy_delimiter='\\t', lazy_labels_column=1, lazy_loading=False, lazy_loading_start_line=1, lazy_text_a_column=None, lazy_text_b_column=None, lazy_text_column=0, onnx=False, regression=False, sliding_window=False, special_tokens_list=[], stride=0.8, tie_value=1)\n",
      "Doing new prediction in V:/Uni/Thesis/Code/Thesis/buttons_model0/\n",
      "Start training 0\n",
      "No model preset, doing training 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\marie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:486: UserWarning: use_multiprocessing automatically disabled as xlmroberta fails when using multiprocessing for feature conversion.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        text                 labels\n",
      "0    0000272            hubspot.com\n",
      "1    0000097              twitch.tv\n",
      "2    0000133  googlesyndication.com\n",
      "3    0000347            weather.com\n",
      "4    0000125                wsj.com\n",
      "..       ...                    ...\n",
      "803  0000350               dell.com\n",
      "804  0000346        marketwatch.com\n",
      "805  0000346        marketwatch.com\n",
      "806  0000247            addthis.com\n",
      "807  0000081        theguardian.com\n",
      "\n",
      "[808 rows x 2 columns]         text           labels\n",
      "0    0000108        issuu.com\n",
      "1    0000161  dailymail.co.uk\n",
      "2    0000123   aliexpress.com\n",
      "3    0000324     marriott.com\n",
      "4    0000131    bloomberg.com\n",
      "..       ...              ...\n",
      "168  0000458          iso.org\n",
      "169  0000008     linkedin.com\n",
      "170  0000345        google.ca\n",
      "171  0000440     outbrain.com\n",
      "172  0000097        twitch.tv\n",
      "\n",
      "[173 rows x 2 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'hubspot.com'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [45], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     model_savedir \u001b[38;5;241m=\u001b[39m model_savedir_buttons\n\u001b[0;32m     10\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuttons\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mXLM_RoBERTA_model_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber_of_runs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_savedir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mV:\\Uni\\Thesis\\Code\\Thesis\\XLM_RoBERTA_model_execution.py:54\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(number_of_runs, classification_filename, model_savedir, model_type)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(datadir):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDoing new prediction in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatadir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 54\u001b[0m     \u001b[43mtraining_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatadir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_group_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_group_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mprediction_group_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m full_predictions(dataset, datadir, training_group_size, eval_group_size, prediction_group_size)\n",
      "File \u001b[1;32mV:\\Uni\\Thesis\\Code\\Thesis\\XLM_RoBERTA_model_execution.py:137\u001b[0m, in \u001b[0;36mtraining_session\u001b[1;34m(i, dataset, datadir, model_args, training_group_size, eval_group_size, prediction_group_size)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_df, eval_df)\n\u001b[1;32m--> 137\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------------model trained--------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------------Doing predictions on small dataset--------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:619\u001b[0m, in \u001b[0;36mClassificationModel.train_model\u001b[1;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    612\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n\u001b[0;32m    615\u001b[0m         train_examples \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    616\u001b[0m             train_df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m    617\u001b[0m             train_df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m    618\u001b[0m         )\n\u001b[1;32m--> 619\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_and_cache_examples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m train_sampler \u001b[38;5;241m=\u001b[39m RandomSampler(train_dataset)\n\u001b[0;32m    623\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m    624\u001b[0m     train_dataset,\n\u001b[0;32m    625\u001b[0m     sampler\u001b[38;5;241m=\u001b[39mtrain_sampler,\n\u001b[0;32m    626\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtrain_batch_size,\n\u001b[0;32m    627\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_num_workers,\n\u001b[0;32m    628\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:1827\u001b[0m, in \u001b[0;36mClassificationModel.load_and_cache_examples\u001b[1;34m(self, examples, evaluate, no_cache, multi_label, verbose, silent)\u001b[0m\n\u001b[0;32m   1825\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[0;32m   1826\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1827\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mClassificationDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1829\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1833\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\simpletransformers\\classification\\classification_utils.py:282\u001b[0m, in \u001b[0;36mClassificationDataset.__init__\u001b[1;34m(self, data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, tokenizer, args, mode, multi_label, output_mode, no_cache):\n\u001b[1;32m--> 282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexamples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_classification_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_cache\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\simpletransformers\\classification\\classification_utils.py:222\u001b[0m, in \u001b[0;36mbuild_classification_dataset\u001b[1;34m(data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[0;32m    220\u001b[0m         labels \u001b[38;5;241m=\u001b[39m [[args\u001b[38;5;241m.\u001b[39mlabels_map[l] \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels]\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 222\u001b[0m         labels \u001b[38;5;241m=\u001b[39m [args\u001b[38;5;241m.\u001b[39mlabels_map[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels]\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39muse_multiprocessing) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    225\u001b[0m     mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39muse_multiprocessing_for_evaluation\n\u001b[0;32m    226\u001b[0m ):\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmultiprocessing_chunksize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\simpletransformers\\classification\\classification_utils.py:222\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    220\u001b[0m         labels \u001b[38;5;241m=\u001b[39m [[args\u001b[38;5;241m.\u001b[39mlabels_map[l] \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels]\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 222\u001b[0m         labels \u001b[38;5;241m=\u001b[39m [\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels]\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39muse_multiprocessing) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    225\u001b[0m     mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39muse_multiprocessing_for_evaluation\n\u001b[0;32m    226\u001b[0m ):\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmultiprocessing_chunksize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hubspot.com'"
     ]
    }
   ],
   "source": [
    "if choice == 1:\n",
    "    number_of_runs = choice_runs\n",
    "    classification_filename = classification_dialog_filename\n",
    "    model_savedir = model_savedir_dialog\n",
    "    model_type = \"cookie dialog\"\n",
    "elif choice == 2:\n",
    "    number_of_runs = choice_runs\n",
    "    classification_filename = classification_buttons_filename\n",
    "    model_savedir = model_savedir_buttons\n",
    "    model_type = \"buttons\"\n",
    "\n",
    "XLM_RoBERTA_model_execution.main(number_of_runs, classification_filename, model_savedir, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "639c2a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] Access is denied: 'V:/Uni/Thesis/Code/Thesis/buttons_model0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_savedir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Access is denied: 'V:/Uni/Thesis/Code/Thesis/buttons_model0'"
     ]
    }
   ],
   "source": [
    "os.remove(model_savedir + '0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
